Simple List Imputer 

from sklearn.impute import SimpleImputer 
import numpy as np

data= np.array([
[1, 2, np.nan ], [4, np.nan, 6],
[np.nan, 8, 9]
])

imputer = SimpleImputer (strategy='mean', fill_value =1)

imputed_data = imputer.fit_transform(data)

print(data) 
print(imputed data)


KNN Imputer
from sklearn.impute import KNNTmputer 
import numpy as np

data = np.array([
[2, 4, np.nan ], 
[5, 1, 6],
Inp.nan, 5, 7), 
[9, 8, 9]
]}

knn_imputer = KNNImputer (n_neighbors=2)

imputed_data = krn_imputer.fit_transform(data)

print(data)
print(imputed data)

Mean Removal

import numpy as np

from sklearn import preprocessing

input_data np.array([[3,-1.5,3,-6.4], [0,3,-1.3,4.1], [1,2.3,-2.9,-4.3]])

data_standardized preprocessing.scale(input_data)

print("\n Mean = ", data_standardized.mean(axis = 0))

print(" Std deviation", data_standardized.std(axis = 0))



Min-Max Scale

import numpy as np

from sklearn import preprocessing

input_data = np.array([[3,-1.5,3,-6.4], [0,3,-1.3,4.1], [1,2.3,-2.9,-4.3]])

data_scaler preprocessing. MinMaxScaler (feature_range = (0,1))

data_scaled data_scaler.fit_transform(input_data)

print("\n Min Max Scaled Data = ", data_scaled)

Normalization 1

import numpy as np

from sklearn import preprocessing

input_data = np.array([[3,-1.5,3,-6.4], [0,3,-1.3,4.1], [1,2.3,-2.9,-4.3]])

data_normalized preprocessing.normalize(input_data, norm = '11')

print("\n L1 Normalized Data = ", data_normalized)

Binarizing

import numpy as np

from sklearn.preprocessing import Binarizer

ages= np.array([[15], [22], [18], [30], [16], [25]])

binarizer Binarizer (threshold = 18)

binary_ages = binarizer.fit_transform(ages)

print(" Original ages: \n",ages)

print(" Binarized ages: \n", binary_ages)


Label Encoding using scikit-learn library

import pandas as pd

from sklearn import preprocessing

my_data = {

"Gender": ['F', 'M', 'M', 'F', 'M', 'F', 'M', 'F', 'F', 'M'],

"Name": ["Krishna', 'Rudra', 'Hrithik', 'Kiara', 'Dhoni', 'Sara', 'Rajesh', 'Lata', 'Anuska', 'Ratan']

}

blk pd.DataFrame(my_data)

print("Genuine Data Frame: \n")

print(blk)

my_label preprocessing. LabelEncoder()

blk['Gender'] = my_label.fit_transform(blk['Gender'])

print(blk['Gender'].unique())

print("Data Frame after Label Encoding: \n")

print(blk)


Case Study Implementation: Predicting House Prices.

import pandas as pd

import numpy as np

from sklearn.model_selection import train_test_split

from sklearn.linear_model import LinearRegression

from sklearn.metrics import mean_squared_error, r2_score

data = (

'Size': [1500, 1600, 1700, 1800, 1900, 2000],

"Bedrooms:

[3, 3, 4, 4, 5, 5],

'Age: [10, 15, 20, 5, 8, 2],

'Price': [300000, 320000, 350000, 400000, 450000, 500000]

df pd.DataFrame(data)

x= df[['Size', 'Bedrooms', 'Age']]

Y = df['Price']

X_train,X_test, Y_train, Y_test train_test_split(X, Y, test_size = 0.2, random_state = 42)

model LinearRegression()

model.fit(X_train, Y_train)

Step 6: Make Predictions.

Y_pred model.predict(X_test)

mse mean_squared_error(Y_test,Y_pred)

r2 r2_score(Y_test,Y_pred)

print("Mean Squared Error: ",mse)

print("R^2 Score: ",r2)

#Output the coefficients.

print("Coefficients: ",model.coef_)

print("Intercept: ", model.intercept
